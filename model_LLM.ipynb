{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt0AJwAMpf3W"
      },
      "outputs": [],
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "import os\n",
        "env = os.environ.copy()\n",
        "env[\"OLLAMA_HOST\"] = \"0.0.0.0\"\n",
        "env[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "import subprocess\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"], env=env)\n",
        "\n",
        "import threading\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "\n",
        "import time\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwdj40jG-xJm"
      },
      "outputs": [],
      "source": [
        "!ollama pull llama3.2:1b\n",
        "!curl http://localhost:11434/api/generate -d '{ \"model\": \"llama3.2:1b\", \"prompt\": \"Who are you?\", \"stream\": false}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cehOgpq4TOId"
      },
      "outputs": [],
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm\n",
        "%xterm\n",
        "\n",
        "# TODO: Chạy lệnh dưới để tunnel ra bên ngoài CHÚ Ý: NHẤN PHẢI RỒI CHỌN COPY TRONG MENU, NẾU BẤM CTRL + C SẼ TẮT KẾT NỐI\n",
        "# ssh -p 443 -R0:localhost:11434 qr@a.pinggy.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8lUFntoGiNs"
      },
      "outputs": [],
      "source": [
        "# Thay \"http://localhost:11434\" bằng link sinh ra từ pingy.io, ví dụ nếu thấy \"http://bsqlv-34-125-123-92.a.free.pinggy.link\"\n",
        "!curl https://onaxx-34-48-5-214.a.free.pinggy.link/api/generate -d '{ \"model\": \"llama3.2:1b\", \"prompt\": \"Tell me a joke\", \"stream\": false}'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
